{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LLM Powered Applications by Valentina Alto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Large Language Models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics covered;\n",
    "1. Understanding LLMs, their differentiators from classical ML systems. \n",
    "2. Overview of the most popular LLM architectures.\n",
    "3. How LLMs are trained and consumed.\n",
    "4. Base LLMs versus fine-tuned LLMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions; \n",
    "- LLMs are deep-learning based models that use many parameters to learn for vast amounts of unlabeled texts. \n",
    "They perform tasks like recognizing, sumarizing, translating, predicting and generating text.\n",
    "- Deep Learning is a branch of machine learning characterized by neural networks with multiple layers, used for extracting abstract features from input data. \n",
    "- Artificial neural networks; are computational models insired by the structure and functioning of the human brain. \n",
    "- Backpropagation is an algorithm used to train neural networks. In the forward pass, the data is passed through the network to compute the output. In the backward pass, the errors are propagated backward to update the network's parameters and improve performance. \n",
    "- Foundation model is a type of pre-trained generative AI model that offers immense versatility by being adaptable for various specific tasks. \n",
    "They undergo extensive traning on vast and diverse datasets, enabling them to grasp general patterns and relationships within data. \n",
    "\n",
    "Foundation models:\n",
    "> Pre-training\n",
    "> Fine-tuning \n",
    "> Transfer learning \n",
    "> Large model architecture \n",
    "> Generalization \n",
    "LLMs; GPT-4, BERT, Megatron, Llama\n",
    "\n",
    "Popular AI ANN Architectures;\n",
    "1. RNN: Used to handle sequential data. Have recurrent connections that allow information to persist across time steps, making it suitable for language modeling, machine translation and text generation. \n",
    "Have a vanishing gradient problem; struggle to capture long-term patterns(small gradient) and unstable training & prevents the RNN from converging to a good solution(exploding gradient-large)\n",
    "2. LSTM: Variants of RNNs that address the vanishing gradient problem. Introduce gating mechanisms that enable better preservation of important information across longer sequences. \n",
    "Popular for sequential tasks eg text generation, speech recognition and sentiment analysis.\n",
    "\n",
    "The archutectures above have limitations in handling long-range dependencies, scalability, and overall efficiency especially when dealing with large-scale NLP tasks that would need massive parallel processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Introducing The Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformer dispenses with recurrence and convolutions entirely and relies solely on attention mechanisms.\n",
    "'Attention' is a mechanism that enables the model to focus on relevant parts of the input sequence while generating the output. \n",
    "- It calculates attention scores between input and output positions, applies Softmax to get weights, and takes a weighted sum of the input sequence to obtain context vectors. \n",
    "- Attention is crucial for capturing long-range dependencies and relationships between words in the data. \n",
    "In transformers, self-attention layers are responsible for determining the importance of each input token in generating the output.\n",
    "To obtain the self-attention vectors for  a sentence, we need;\n",
    "1. Query(Q): Used to represent the current focus of the attention mechanism. \n",
    "2. Key(K): Used to determine which parts of the input should be given attention. \n",
    "3. Value(V): Used to compute the context vectors. \n",
    "These matrices are used to calcuate attention scores between the elements in the input sequence and are the three weight matrices that are learned during the training process. \n",
    "The transformer has two main components: \n",
    "> Encoder; takes the input sequence and produces a sequence of hidden states, each of which is a weighted sum of all the input embeddings. \n",
    "> Decoder; Takes the output sequence(shifted right by one position) and produces a sequence of predicitions, ie a weighted sum of all the encoder's hidden states and the previous decoder's hidden states. \n",
    "\n",
    "Some models use the encoder only eg BERT(Bidirectional Encoder Representations from Transformers). Designed for NLU tasks like text classification, question answering and sentiment analysis. \n",
    "Other models use decoder part eg GPT-3(Genetative Pre-trained Transformer 3). Designed for NLG tasks like text completion, summarization and dialog. \n",
    "Some models use both encoder and decoder parts eg T5(Text-to-Text Transfer Transformer), designed for NLP tasks framed as text-to-text transformations eg translation, paraphrasing, and text simplification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Training and Evaluating LLMs \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an LLM; \n",
    "> Number of parameters; Measures the complexity of the LLM architecture and represents the number of connections among neurons. \n",
    "> Training set; Refers to the unlabeled text corpus on which the LLM learns and trains its parameters.\n",
    "1 token ~= 4 English characters \n",
    "1 token ~= 3/4 words \n",
    "Training is done on distributed systems with multiple graphics processing units(GPUs) or tensor processing units (TPUs).\n",
    "A tensor is a multi-dimensional array used to hold numerical data. \n",
    "- Main training steps:\n",
    "1. Data collection; Gathering a large amount of data from varous sources. Should be diverse, high-quality and representative. \n",
    "2. Data preprocessing; Process of cleaning, filtering, and formatting the data for training. May include removing duplicates, noise, sensitive information, splitting the data into paragraphs, tokenizing the text into subwords/characters. \n",
    "3. Model architecure; Designing the structure and parameters of the LLM. Choose the type of neural network(eg transformer), its structure(decoder only, encoder only, encoder-decoder), number  and size of layers, the attention mechanisms and activation functions. \n",
    "4. Model initialization; Assigning initial values to the weights and biases of the LLM. Can be random/ using pre-trained weights from another model. \n",
    "5. Model pre-training; Process of updating weights and biases of the LLM by feeding it batches of data and computing the loss function. \n",
    "The loss function measures how the well the LLM predicts the next token given the previous tokens. \n",
    "The LLM tries to minize loss by using an optimization algorithm(gradient descent-SGD) that adjusts weights and biases in the direction that reduces loss with backpropagation. \n",
    "6. Fine-tuning:; Base model is trained in a supervised way with a dataset made of tuples of (prompt, ideal response). Makes the base model inline with AI assistants. \n",
    "The output is a supervised fine-tined(SFT) model. \n",
    "7. Reinforcement learning from human feedbach(RLHF); Iteratively optimizing the SFT model by updating some of its parameters wrt the reward model(typically another LLM trained incorporating human preferences).\n",
    "\n",
    "- Model Evaluation \n",
    "Evaluating an LLM involves measuring its language fluency, coherence, and ability to emulate different styles depending on the user's request. \n",
    "1. General Language Understanding Evaluation(GLUE): Measures the performance of LLMs on various NLU tasks. The higher the score of GLUE benchmark, the better the LLM in generalizing across different domains and tasks.\n",
    "Focuses on grammar, paraphrasing and text similarity.\n",
    "SuperGLUE is more challenging and realistic than GLUE and convers complex tasks and phenomena. \n",
    "2. Massive Multitask Language Understanding(MMLU): Measures the knowledge of an LLM using zero-shot and few-shot setting. \n",
    "Zero-shot evaluation measures how well the language model can perform on a new tasks by using natural language instructions/examples as prompts and computing the likelihood of the correct output given the input. \n",
    "Focuses on generalized language understanding among various domains and tasks. \n",
    "3. HellaSwag: Evaluates LLMs on their ability to generate plausible and common sense continuations for given contexts. \n",
    "4. TruthfulQA: Evaluates a language model's accuracy in generating responses to questions. The questions mimic those that humans might answer incorrectly due to false beliefs/misunderstanding. \n",
    "5. AI2 Reasoning Challenge(ARC): Measures LLMs' reasoning capabilities and to simulate the dev't of models that can perform complex NLU tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to customize your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Extending non-parametric knowledge: The allows the model to access external sources of information to integrate its parametric knowledge while responding to the user's query. \n",
    "-Parametric knowledge is the one embedded in the LLM's parameters, deriving from unlabeled text corpora during training. \n",
    "- Non-parametric knowledge is the one we can 'attach' to the model via embedded documentation. Doesn't change the structure of the model but allows it to navigate through external documentation to be used as relevant context to answer the user's query. \n",
    "> Few-shot learning: The LLM is given a metaprompt with a small number of examples of each new task it is asked to perform. \n",
    "A metaprompt is a message/instruction used to improve the performance of LLMs on new tasks with a few examples. \n",
    "> Fine tuning: Involves using smaller, task-specific datasets to customize the foundation models for particular apps. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations for integrationg LLMs within Applications\n",
    "1. Technical aspect: covers the how. Involves embedding them through REST API and manage them with AI orchestrators(helps to efficiently manage and coordinate the LLMs' functionality within the app).\n",
    "2. Conceptual aspect: Covers the what. Bringing a LLM capabilities that can be harnessed within the applications. This highlights the significant assistance and collaboration provided by LLMs in enhancing app functionalities. \n",
    "\n",
    "- Grounding involves using an LLM with information that us use case specific, relevant and not available as part of the LLM's trained knowledge. This ensures quality, accuracy and relevance. \n",
    "This can be achieved through retrieval-augmented generation(RAG).\n",
    "\n",
    "> LLM Limitations\n",
    "- Limited parametric knowledge: Have a knowledge base cutoff date. \n",
    "- Lack of executive power: LLMs are not empowered to carry out actions. \n",
    "\n",
    "Prompt engineering: Process of designing and optimizing prompts to LLMs for a wide variety of applications and research topics.\n",
    "Involves sepecting the right words, phrases, symbols and formats that elicit the desired response from the LLM. \n",
    "Prompts: Short pieces of text used to guide an LLMs' output. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AI Orchestrators \n",
    "VectorDB: A database that stores and retrieves information based on vectorized embeddings, the numerical representations that capture the meaning and context of text. \n",
    "eg Chroma, Elasticsearch, Milvus, Pinecone, Qdrant, Weaviate, FAISS(Facebook AI Similarity Search).\n",
    "1. Langchain: Framework for developing apps powered by language models, making them data-aware and agentic. \n",
    "Modules;\n",
    "- Models: Are the LLMs and LFMs that are engine of the app. Supports proprietary  and open-source models. \n",
    "- Data connectors: Building blocks needed to retrieve additional external knowledge eg document loaders and text embedding models. \n",
    "- Memory: Allows the app to keep references to the user's interactions, both long and short term. Based on vectorized embeddings stored in a VectorDB. \n",
    "- Chains: Predetermined sequences of actions and calls to LLMs that make it easier to build complex applications that require chaining LLMs with each other/other components.\n",
    "- Agents: Entities that drive decision making within LLM-powered apps. Have access to a suite of tools and can decide which tools to call based on the user input and context.\n",
    "\n",
    "2. Haystack: A framework developed by Deepset that provides devs with tools to build NLP-base  apps. \n",
    "- Nodes: Components that perform a specific task/function eg as a retriever, a reader, a generator, a summarizer etc.\n",
    "- Pipelines: Sequences of calls to nodes that perform natural language tasks/interact with other resources. Can be querying pipelines or indexing pipelines depending on whether they perform searche on a set of documents/prepare documents for search.\n",
    "Are predetermined and handcoded hence don't change/adapt basedon the user input/context.\n",
    "- Agent: Uses LLMs to generate accurate responses to complex queries. Can access a set of tools eg pipelines, nodes and decide which tool to call base on user input/context. \n",
    "- Tools: Are functions that an agent can call to perform natural language tasks/interact with other resources. Can either be pipelines/nodes. \n",
    "- DocumentStores: Are backends that store and retrieve documents for searches. Can be a VectorDB(FAISS, Milvus, ElasticSearch)\n",
    "\n",
    "3. Semantic Kernel: An open-source SDK developed by Microsoft.\n",
    "A kernel is meant to act as the engine that addresses a user's input by chaining and concatenating a series of components into pipelines, encouraging function composition.\n",
    "- Models: LLMs/FLMs that will be the engine of the app. Supports both proprierary and open-source models. \n",
    "- Memory: Allows the app to keep references to the user's interactions, both in the short  and long term. Memories can be accessed as: \n",
    "  > Key-value pairs- Saving env variables that store simple information. \n",
    "  > Local storage - Consists of saving information to a file that can be retrieved bt its filename. \n",
    "  > Semantic memory search - Uses embeddings to represent and search for text information basd on its meaning.\n",
    "- Functions: Skills that minx LLM promts and code, with the goal of making the user's ask interpretable and actionable. \n",
    "  > Semantic fuctions- A type of templated prompt, a natural language query that specifies the input and output format of the LLM. \n",
    "  > Native functions- Native computer code that can route the intent captured by the semantic function and perform the related task.\n",
    "- Plug-ins: Connectors toward external sources/systems that are meant to provide additional information/ the ability to perform autonomous actions. eg Microsoft Graph connector kit. \n",
    "- Planner: A function that takes as input a user's task and producs a set of actions, plug-ins, and functions needed to achieve the goal. Auto-create chains/pipelines to address new user's needs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to choose a framework \n",
    "1. The programming language you are comfortable with/prefer to use. One that matches your existing skills/preferences. \n",
    "2. The type and complexity of the natural language tasks you want to perform/support. eg summarization, translation and reasoning. \n",
    "3. The level of customization and control you want over LLMs and their parameters/options. Different ways of accessing, configuring and fine-tuning ahd their parameters/options like model selection, prompt design, inference speed and output format. \n",
    "4. The availability and quality of the documentation, tutorials, examples and community support for framework. This helps you to get started and solve problems with the framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different LLMs ahave different architectures, sizes, training data, capabilities and limitations. Choosing the right one impacts performance, quality, and cost of the solution.\n",
    "1. Propritary Models\n",
    "Offer better  support and maintainane as well as safety an alignment. Outperform open-source models on generalization but act as a 'black box'.\n",
    "> GPT-4: Develped by OpenAI, belongs to generative pretrained transformer(GPT) models, a decoder-only transformer-based architecture. \n",
    "- The model is aligned based on RLHF training. Other training methods; unsupervised pretraining, supervised fine-tuning, instruction tuning. \n",
    "- The model has limited hallucination; a phenomenon where the LLM generate text that is incorrect, nonsensical, not real but appears to be plausible/coherent. This because the LLMs are based on statistical models that learn from massive amounts of data and produce outputs based on patterns and probabilites learnt. The data many not represent reality due to it being incompelete, noisy or biased.\n",
    "- Alignment describes the degree to which LLMs behave in ways that are useful and harmless for their human users. An LLM is aligned if it generates text that is accurate, relevant, coherent and respectful. \n",
    "- The LLM is misaligned if it generates text  that is false, misleading, harmful and offensive. \n",
    "\n",
    "> Gemini 1.5: A state-of-the-art GenAI model developed by Google. Its multimodal hane can process and generate content  in text, images, audo, video and code. \n",
    "Based on a mixture-of-expert(MoE) transfomer. \n",
    "- MoE refers to  a model that incorporates multiple specialized sub-models 'experts' within it layers. Uses a gating mechanism/router to determine which expert should process a given input, allowing the model to dynamically allocate resources and specialize in processing certain types of information. \n",
    "Gemini comes in sizes like Ultra, Pro and Nano to catter for different computational needs. \n",
    "\n",
    "> Claude 2: Constitutional Language-scale Alignment via User Data and Expertise(CLAUDE). Developed by Anthropic with focus on AI safety and alignment. \n",
    "- Claude 2 is a transformer-based LLM that's trained via unsupervised learning, RLHF and constitutional AI(CAI). \n",
    "- CAI aims to make the model safer and more aligned with human values and intentions by preventing toxic/discriminatory output and broadly creating an AI system that is helpful, honest and harmless. Scored over 71% on the HumanEval benchmark\n",
    "-HumanEval is a benchmark for evaluating the code generation ability of LLMs. This measures functional correctness, syntactic validity, and semantic coherence in the LLM's outputs. \n",
    "\n",
    "2. Open-source Models \n",
    "This implies; \n",
    " - You have major control over the architecture, you can modify it in your local version. \n",
    " - Polisibility of training the moel from scratch, on top of classical fine-tuning. \n",
    " - Free to use. \n",
    "> LLaMA-2: Large Language Model Meta AI 2, developed by Meta. It is an autoregressive model with an optimized decoder-only transformer architecture. \n",
    "- Autoregressive for the fact that the model predicts the next token in the sequence, conditioned on all previous tokens. Done by masking the input. \n",
    "- Base models: Trained on vast amounts of data often from the internet. Primary function is to predict the next word in a given context and may not always be precise/focused on specific instructions. \n",
    "- Assistant models: start as base LLMs but are further fine-tuned with input-output pairs that include instructions and the model tries to follow those instructions. Often emply RLHF to refine the model, making it better at being helpful, honest and harmless. \n",
    "> Falcon LLM: A lighter model(few parameters) and focused on quality of the training dataset. Launched by the Technology Innovation Institute(TII). \n",
    "- It's an autoregressive, decoder-only transformer. Also comes with an fine-tuned variant called 'Instruct' tailored towards following user instructions. \n",
    "- Instruct models are specialized for short-form instruction following. Trained on large datasets of instructions and their correspoding outputs.\n",
    "> Mistral: Developed by MistralAI and emphasizes transparency and accessiblity in AI development. \n",
    "- Mistral model is a decoder-only transformer model designed for generative text tasks. Known for innovative architectures like: \n",
    " -> grouped-query attention(GQA): Allows for faster inference times to standard full attention mechanisms. Partitions attention mechanism's query heads into groups with each group sharing a single key and value head.\n",
    " -> sliding-window attention(SWA): Used to handle long text sequences efficiently. Extends the model's attention beyond fixed window size, allowing each layer to reference a range of positions from the preceding layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Choosing the right LLM \n",
    "1. Size and performance: Complex models tend to have better performance in terms of parametric knowledge and generalization capabilities. \n",
    "For large models, more computation an memory is required to process user input. \n",
    "2. Cost and hosting strategy: \n",
    "   > Cost of model consumption: Fee for consuming the model. Proprietary models require a fee in proportional to the number of tokens processed. \n",
    "   > Cost of model hosting: Proprietary models are hosted in private/public hyperscaler and are consumed via a REST API. Open-source models need own infrastructure or using HuggingFace Inference API. \n",
    "3. Customization: \n",
    "   > Fine-tuning: Slightly adjusting LLMs's parameters to better fit the domain. Open-source models can be fine-tuned while for proprietary models, not all can be fine-tuned. \n",
    "   > Training from scratch: For super specific models, you might want to train from scratch by having them downloaded locally. Not possible for proprietary models. \n",
    "4. Domain-specific capabilities: Use a model that is a top performer in a specific benchmark eg MMLU for LLMs' generalization culture and commonsense reasoning, TruthfulQA for LLMs' alignment, HumanEval for LLMs' coding capabilities. \n",
    "This saves in terms of model complexity for relatively small models. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt engineering: Process of designing effective prompts that elicit high-quality and relevant output from LLMs. \n",
    "\n",
    "Principles: \n",
    " - Clear instructions. Goal/objective of task, format/structure of output, constraints, and context/background of the task. \n",
    " - Split complex tasks into subtasks. \n",
    " - Ask for justification\n",
    " - Generate many outputs, then use the model to pick on the best one. \n",
    " - Repeat instructions to the end. \n",
    " Recency bias: Tendency of the LLM to give more weight to the information that appears near the end of a prompt, and ingore/forget the information that appears earlier. This leads to inaccurate/inconsitent responses that don't take into a/c the whole context of the task.\n",
    " - Use delimiters eg a any sequence of characters/symbols that is clearly mapping a schema rather than a concept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Techniques "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Few-shot approach\n",
    "- Providing the model with examples of how we would like it to respond. THis enables model customization without interfering with the overall architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CoT\n",
    "- Chain of Thought(CoT) is a technique that enables complex reasoning capabilities through intermediate reasoning steps. \n",
    "- It encourages the model to expain its reasoning 'forcing' it not to be too fast and risk giving wrong responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ReAct\n",
    "\n",
    "ReAct(Reason and Act) is a paradigm that combines reasoning and acting with LLMs. \n",
    "- It prompts the language model to generate verbal reasoning traces and actions fora task, and also receives observations from external sources eg web searches/DBs. \n",
    "- This allows the language model to perform dynamic reasoning and adapt its action plan based on external information. \n",
    "- CoT prompts the model to generate intermediate reasoning steps for a task while ReAct prompts the model to generate intermediate reasoning steps, actions and observations for a task. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent \n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.tools import Tool \n",
    "# from langchain.schema import HumanMessage \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# SerpAPI Key \n",
    "key = os.getenv(\"SERPAPI_API_KEY\")\n",
    "# MistralAI Key\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "# Initialize Mistral chat model \n",
    "model = ChatMistralAI(\n",
    "    model_name=\"mistral-large-latest\",\n",
    "    api_key=mistral_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search(query: str, **kwargs: Any) -> str - useful for when you need to answer questions about            current events.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "search = SerpAPIWrapper()\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func = search.run, \n",
    "        name='Search', \n",
    "        description = \"useful for when you need to answer questions about\\\n",
    "            current events.\"\n",
    "    )\n",
    "]\n",
    "agent_executor = initialize_agent(\n",
    "    tools,\n",
    "    model, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(agent_executor.agent.llm_chain.prompt.template, end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `stop` not yet supported (https://docs.mistral.ai/api)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find out what \"deepseek\" is.\n",
      "\n",
      "Action: Search\n",
      "Action Input: deepseek\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `stop` not yet supported (https://docs.mistral.ai/api)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Baidu Releases Reasoning AI Model to Take On DeepSeek', 'link': 'https://www.bloomberg.com/news/articles/2025-03-16/baidu-releases-reasoning-ai-model-to-take-on-deepseek', 'source': 'Bloomberg.com', 'date': '1 day ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad28fc4cebb22b1c6e5290803d5207dfa6bb.jpeg'}, {'title': 'Stock of the Day: Baidu jumps after it releases an AI model to rival DeepSeek', 'link': 'https://www.businessinsider.com/baidu-stock-price-deepseek-ai-tool-china-tech-ernie-x1-2025-3', 'source': 'Business Insider', 'date': '1 hour ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad28073430920be7e82efd7073668282203d.jpeg'}, {'title': \"China's Baidu Takes on DeepSeek With New AI Model\", 'link': 'https://finance.yahoo.com/news/chinas-baidu-takes-deepseek-ai-115807656.html', 'source': 'Yahoo Finance', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad287ecc215d619e9f0f9f50d43f19381ef0.jpeg'}, {'title': 'DeepSeek developers now under travel restrictions from China', 'link': 'https://novyny.live/en/tehnologii/u-tvortsiv-shi-z-kompaniyi-deepseek-pochali-viluchati-pasporti-240826.html', 'source': 'Новини Live', 'date': '44 minutes ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad28d0ccc959273d3b02f3dc24f164a7ebfb.jpeg'}, {'title': \"China declares DeepSeek 'national treasure': What does it mean?\", 'link': 'https://www.newsbytesapp.com/news/science/china-s-ai-company-deepseek-declared-national-treasure/story', 'source': 'NewsBytes', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad289d34b9c03d896a851bbf0dd09339cb3e.jpeg'}, {'title': \"How DeepSeek's Exclusive AI Development Strategy Fuels Its Growth and Success - News and Statistics\", 'link': 'https://www.indexbox.io/blog/deepseeks-strong-focus-on-ai-development-closes-gap-for-industry-leadership/', 'source': 'IndexBox', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad2845a3e451e705a60ed9708b2694ecc023.jpeg'}, {'title': 'AMD’s Ryzen AI MAX+ 395 “Strix Halo” APU Is Over 3x Faster Than RTX 5080 In DeepSeek R1 AI Benchmarks', 'link': 'https://wccftech.com/amd-ryzen-ai-max-395-strix-halo-apu-over-3x-faster-rtx-5080-in-deepseek-benchmarks/', 'source': 'Wccftech', 'date': '1 hour ago', 'thumbnail': 'https://serpapi.com/searches/67d82b27e3601ec73b89b8fe/images/f35fd0ae2daaad288dfae9c6bb07a0215d51f81e349963a8.jpeg'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the search results, DeepSeek appears to be an AI company or model. Several articles mention Baidu releasing an AI model to rival DeepSeek, indicating that DeepSeek is likely a significant player in the AI industry. Additionally, there are references to DeepSeek being declared a \"national treasure\" by China and facing travel restrictions, which suggests it is a high-value entity.\n",
      "\n",
      "Thought: I now know the final answer\n",
      "Final Answer: DeepSeek is an AI company or model that is significant in the AI industry. It has been declared a \"national treasure\" by China and is a rival to Baidu's AI models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's deepseek\",\n",
       " 'output': 'DeepSeek is an AI company or model that is significant in the AI industry. It has been declared a \"national treasure\" by China and is a rival to Baidu\\'s AI models.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor(\"What's deepseek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding LLMs within Your Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain(LangChain Expression Language-LCEL): \n",
    "1. Streaming asynchronous support: Allows effienct handling of data streams. \n",
    "2. Batch support: Enables processing data in batches. \n",
    "3. Parallel execution: Enhances performance by executing tasks concurrently. \n",
    "4. Retries and fallbacks: Ensure robust error handling of failures gracefully.\n",
    "5. Dynamically routing logic: Allows logic flow based on input and output. \n",
    "6. Message history: Keeps track of interactions for context-aware processing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prompt template: A component that defines how to generate a prompt for a language model. \n",
    "It can include variables, placeholders, prefixes, suffixes and customizations based on task and data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: the cat is on the table\n",
      "Translation in spanish:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate \n",
    "\n",
    "template  = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template,\n",
    "    input_variables=['sentence', 'language'])\n",
    "\n",
    "print(prompt.format(sentence='the cat is on the table', language='spanish'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A completion model is a type of LLM that takes a text input and generates a text output. \n",
    "It ties to continue the prompt in a coherent and relevant way, according to the task and data trained on. \n",
    "> A chat model is a special completion model that is designed to generate conversational responses. Takes a list of messages as input, where each message has a role(system/assistant) and content. \n",
    "Tries to generate new messages for the assistant role, based on previous messages and system instructions. \n",
    "- A completion model expects a sigle input as prompt, while a chat model expects a list of messages as input. \n",
    "\n",
    "In LangChain, an example selector allows one to choose which examples to include in a prompt for a language model. \n",
    "eg: {\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data connections; Building blocks needed to retrieve additional non-parametric knowledge we want to provide the model with.\n",
    "\n",
    "(a). Document Loaders: Load documents from different sources eg csv,file directory, HTML, JSON, Markdown and PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data/sample.csv', 'row': 0}, page_content='Name: John\\nAge: 25\\nCity: New York'), Document(metadata={'source': 'data/sample.csv', 'row': 1}, page_content='Name: Emily\\nAge: 28\\nCity: Los Angeles'), Document(metadata={'source': 'data/sample.csv', 'row': 2}, page_content='Name: Michael\\nAge: 22\\nCity: Chicago')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "\n",
    "\"\"\"Detect filename encording\n",
    "import chardet\n",
    "\n",
    "with open('filename', 'rb') as f:\n",
    "    print(chardet.detect(f.read()))\n",
    "\"\"\"\n",
    "loader = CSVLoader(file_path=\"data/sample.csv\", encoding=\"UTF-8-SIG\")\n",
    "data = loader.load() \n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b). Document transformers: eg text splitters for splitting documents into chunks that are semantically related to reduce context loss and relevant information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.'\n",
      "page_content='The crisp mountain air carries whispers of tranquility, while the rustling leaves compose a'\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"data/mountain.txt\") as f: \n",
    "    mountain = f.read() \n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter( \n",
    "    chunk_size=100, \n",
    "    chunk_overlap=20, \n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([mountain])\n",
    "\n",
    "print(texts[0])\n",
    "print(texts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amidst the serene landscape, towering mountains stand as majestic guardians of nature's beauty.\n"
     ]
    }
   ],
   "source": [
    "print(texts[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c). Text embedding models; Used for incorporating non-parametric knowledge into LLMs and then stored in a VectorDB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embed documents: \n",
      "Number of vector: 1; Dimension of each vector:       1024\n",
      "Embed query: \n",
      "Dimension of the vector: 1024\n",
      "Sample of the first 5 elements of the vector: [0.007228851318359375, 0.01021575927734375, 0.046600341796875, -0.013275146484375, 0.045379638671875]\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "embedding_model = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\"\n",
    ")\n",
    "\n",
    "embeddings = embedding_model.embed_documents(\n",
    "    [\n",
    "        texts[0].page_content\n",
    "    ]\n",
    ")\n",
    "print(\"Embed documents: \")\n",
    "print(f\"Number of vector: {len(embeddings)}; Dimension of each vector: \\\n",
    "      {len(embeddings[0])}\")\n",
    "\n",
    "embed_query = embedding_model.embed_query(\n",
    "    \"What is the text saying?\"\n",
    ")\n",
    "\n",
    "print(\"Embed query: \")\n",
    "print(f\"Dimension of the vector: {len(embed_query)}\")\n",
    "print(f\"Sample of the first 5 elements of the vector: {embed_query[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d). Vector Store: A database that can store and search over unstructured data by using embeddings. With embeddings, vector stores can perform fast and acurate similarity search. \n",
    "eg Facebook AI Similarity Search(FAISS), ElasticSearch, MongoDB Atlas and Azure Search.\n",
    "\n",
    "- Similarity is the measure of how close/related two vectors are in a vector space. In LLMS, vectors are numerical representations of sentences, words/documents that capture semantic meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry to hear that. May I ask your name?\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader \n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "\n",
    "raw_documents = TextLoader('data/dialogue.txt').load() \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=0, \\\n",
    "                    separators='\\n',)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "query = \"What is the reason for calling?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e). Retrievers: A retriever is a component that can return documents relevant to an unstructured query. eg natural language question/ a keyword.\n",
    "Methods used include keyword matching, semantic search and ranking algorithms. \n",
    "A retriever can use any method to find relevant documents and can use different sources of documents eg webpages, DB or files  while a vector store relies on embeddings and needs to store the data itself. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The reason for the call is to report an accident.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = db.as_retriever() \n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm = model, chain_type=\"stuff\", \n",
    "        retriever=retriever)\n",
    "\n",
    "query = \"What is the reason of the call?\"\n",
    "qa.run(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Memory\n",
    "\n",
    "Memory allows the application to keep references to user interactions, both in the short  and long term. \n",
    "- Conversation buffer memory: Allows storage of chat messages and extract them in a variable. \n",
    "- Conversation buffer window memory: Allows a sliding window over only K interactions so that you can manage longer chat time. \n",
    "- Entity memory: Allows the language model to remember given facts about specific entities in a conversation. \n",
    "- Conversation knowledge graph memory: Uses a knowledge graph to recreate memory. \n",
    "- Conversation summary memory: Creates a summary of the conversation over time. \n",
    "- Conversation summary buffer memory: Combines buffer and conversation summary memory. \n",
    "- Conversation token buffer memory: Uses token lengths rather than number of interactions to determine when to start summarizing the interactions. \n",
    "- Vector store-backed memory: Leverages embeddings and vector stores. Stores interactions as vectors, and retrieves the top K most similar texts using a retriever.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'The human greets and expresses they are looking for ideas to write an essay on AI. The AI suggests writing about Large Language Models (LLMs).'}"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=model)\n",
    "memory.save_context(\n",
    "    {\"input\": \"hi, am looking for some ideas to write an essay in AI.\"},\n",
    "    {'output': \"Hello, what about writing about LLMs.\"}\n",
    ")\n",
    "print(memory.load_memory_variables({}), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Chains \n",
    "\n",
    "Are predefined sequences of actions and calls to LLMs that make it easier to build complex apps that require combining LLMs with each other/components. \n",
    "- LLMChain: Consists of a prompt template, an LLM and an optional output parser. \n",
    "The output parser structures language model responses. Uses get_format_instructions and parse methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of the sentence \"The cat is on the table\" in Spanish is:\n",
      "\n",
      "\"El gato está en la mesa.\"\n",
      "\n",
      "Here's a breakdown:\n",
      "- \"The cat\" = \"El gato\"\n",
      "- \"is\" = \"está\"\n",
      "- \"on the table\" = \"en la mesa\""
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = \"\"\"Sentence: {sentence}\n",
    "Translation in {language}:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, \n",
    "            input_variables=[\"sentence\", 'language'])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=model)\n",
    "\n",
    "print(llm_chain.predict(sentence=\"the cat is on the table\", language=\"spanish\"), end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RouterChain: \n",
    "\n",
    "Allows you to route the input variables to different chains based on some conditions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cisige\\AppData\\Local\\Temp\\ipykernel_6436\\1018153309.py:45: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
      "c:\\Users\\cisige\\Documents\\ICEA LION\\LLMs\\agents\\agents_env\\Lib\\site-packages\\pydantic\\main.py:214: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "C:\\Users\\cisige\\AppData\\Local\\Temp\\ipykernel_6436\\1018153309.py:57: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "itinerary: {'input': \"I'm planning a trip from Milan to Venice by car. What can I visit in between?\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': \"I'm planning a trip from Milan to Venice by car. What can I visit in between?\", 'text': 'That sounds like a wonderful trip! Driving from Milan to Venice offers a variety of interesting stops along the way. Here are some recommendations to create an optimized itinerary based on popular attractions and scenic routes:\\n\\n### Day 1: Milan to Verona\\n1. **Depart from Milan**\\n   - Start your journey from Milan.\\n\\n2. **Verona**\\n   - **Juliet\\'s Balcony**: Visit the famous balcony associated with Shakespeare\\'s \"Romeo and Juliet.\"\\n   - **Verona Arena**: An ancient Roman amphitheater that hosts opera performances.\\n   - **Piazza delle Erbe**: A historic square with a market and beautiful architecture.\\n   - **Castelvecchio**: A medieval castle with a museum.\\n\\n   - **Overnight in Verona**: Enjoy the evening exploring the charming streets and trying local cuisine.\\n\\n### Day 2: Verona to Padua\\n1. **Depart from Verona**\\n\\n2. **Soave**\\n   - **Soave Castle**: A picturesque medieval castle in the town of Soave.\\n   - **Wine Tasting**: Enjoy some local wine tasting in the Soave wine region.\\n\\n3. **Vicenza**\\n   - **Villa Capra \"La Rotonda\"**: A UNESCO World Heritage Site and one of Andrea Palladio\\'s masterpieces.\\n   - **Basilica Palladiana**: Another architectural marvel by Palladio.\\n\\n4. **Padua**\\n   - **Scrovegni Chapel**: Famous for its frescoes by Giotto.\\n   - **Basilica of Saint Anthony**: A major pilgrimage site.\\n   - **Palazzo della Ragione**: A historic town hall with a large frescoed hall.\\n\\n   - **Overnight in Padua**: Explore the university town and enjoy local cuisine.\\n\\n### Day 3: Padua to Venice\\n1. **Depart from Padua**\\n\\n2. **Arrive in Venice**\\n   - **Rialto Bridge**: A famous bridge over the Grand Canal.\\n   - **St. Mark\\'s Basilica**: A stunning example of Byzantine architecture.\\n   - **Doge\\'s Palace**: A Venetian Gothic palace and former residence of the Doge of Venice.\\n   - **Gondola Ride**: Experience a classic gondola ride through the canals.\\n\\n   - **Overnight in Venice**: Enjoy the unique atmosphere of the city.\\n\\n### Optional Stops\\n- **Lake Garda**: If you have an extra day, consider a detour to Lake Garda for beautiful landscapes and relaxing activities.\\n- **Veneto Wine Region**: Explore the Prosecco wine region for wine tasting and scenic drives.\\n\\n### Tips\\n- **Driving Time**: The total driving time from Milan to Venice is approximately 3.5 hours, but with stops, it can easily extend to 2-3 days.\\n- **Accommodation**: Book your accommodations in advance, especially in popular destinations like Venice.\\n- **Weather**: Check the weather forecast and pack accordingly.\\n\\nThis itinerary provides a mix of historical sites, cultural experiences, and scenic drives, ensuring a well-rounded trip. Enjoy your journey!'}"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain \n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.llm import LLMChain \n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "\n",
    "itinerary_template = \"\"\"You are a vacation iteneraty assistant. \\\n",
    "You help customers find the best destinations and itinerary. \\\n",
    "You help customer create an optimized itinerary based on their \n",
    "references. \n",
    "\n",
    "Here is the question: \n",
    "{input}\"\"\"\n",
    "\n",
    "restaurant_template= \"\"\"You are a restaurant booking assistant. \\\n",
    "You check with customers number of guests and food preferences. \\\n",
    "You pay attention whether there are special conditions to take into \n",
    "account. \n",
    "    \n",
    "Here is the question: \n",
    "{input}\"\"\"\n",
    "\n",
    "llm = model \n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"itinerary\",\n",
    "        \"description\": \"Good for creating itinerary\",\n",
    "        \"prompt_template\": itinerary_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"restaurant\",\n",
    "        \"description\": \"Good for help customers booking at restaurant\",\n",
    "        \"prompt_template\": restaurant_template,\n",
    "    },\n",
    "]\n",
    "\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")\n",
    "\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")\n",
    "print(chain.invoke(\"I'm planning a trip from Milan to Venice by car. What can I visit in between?\"),end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SequentialChain \n",
    "\n",
    "Allows you to execute multiple chains in a sequence. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mWhat do you call a cat that was caught by the police?\n",
      "\n",
      "The purrpatrator.\n",
      "\n",
      "And what do you call a dog that can do magic?\n",
      "\n",
      "A labracadabrador!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mWhat do you call a cow that plays guitar?\n",
      "\n",
      "A *heifer* metal guitarist!\n",
      "\n",
      "What about a chicken that works at a bank?\n",
      "\n",
      "A *fowl*-ler!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Cats and Dogs', 'output': 'What do you call a cow that plays guitar?\\n\\nA *heifer* metal guitarist!\\n\\nWhat about a chicken that works at a bank?\\n\\nA *fowl*-ler!'}"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "template = \"\"\"You are a comedian. Generate a joke following\n",
    "{topic}\n",
    "Joke:\"\"\"\n",
    "prompt_template= PromptTemplate(input_variables=[\"topic\"],\n",
    "template=template)\n",
    "joke_chain = LLMChain(llm=model, prompt=prompt_template)\n",
    "\n",
    "template = \"\"\"You are a translator. Given a text input, translate it to \n",
    "{language}\n",
    "Translation:\"\"\"\n",
    "promt_template = PromptTemplate(\n",
    "    input_variables=[\"language\"], \n",
    "    template=template\n",
    ")\n",
    "translator_chain = LLMChain(llm=model, prompt=prompt_template)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[joke_chain, translator_chain], verbose=True)\n",
    "translated_joke = overall_chain.invoke(\"Cats and Dogs\")\n",
    "\n",
    "print(translated_joke, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TransformationChain \n",
    "\n",
    "Allows you to transform the input variables/output of another chain using some fuctions/expressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"\\nThe Cat and the Dog\\n\\nThere was once a cat and a dog who lived in the same house. They did not get along very well, as they often fought over food, toys, and attention. The cat was clever and cunning, while the dog was loyal and friendly. The cat liked to tease the dog, and the dog liked to chase the cat.\\n\\nOne day, the cat decided to play a prank on the dog. He found a ball of yarn and tied it around the dog's tail. Then he hid behind a sofa and waited for the dog to notice. When the dog saw the yarn, he thought it was a toy and started to play with it. He ran around the house, trying to catch the yarn with his mouth. But every time he got close, the yarn moved away from him. The cat laughed silently as he watched the dog's futile attempts.\\n\\nThe dog soon realized that something was wrong. He looked behind him and saw that the yarn was attached to his tail. He tried to pull it off, but it was too tight. He felt angry and embarrassed. He wondered who did this to him. He sniffed the air and detected the cat's scent. He knew it was the cat who tricked him. He growled and ran towards the sofa where the cat was hiding.\\n\\nThe cat heard the dog's growl and saw him coming. He panicked and ran away from the sofa. He hoped to find a safe place to hide, but he was too late. The dog was faster and caught up with him. He grabbed the cat by the scruff of his neck and shook him hard. The cat yowled and scratched the dog's face. The dog barked and bit the cat's ear. They rolled on the floor, biting and clawing each other.\\n\\nThe noise they made woke up their owner, who was sleeping upstairs. She came down and saw them fighting. She was shocked and angry. She shouted at them to stop. She grabbed a broom and hit them lightly on their heads. They stopped fighting and looked at her with fear. She scolded them for being naughty and making a mess. She untied the yarn from the dog's tail and threw it away. She took them to the bathroom and cleaned their wounds. She told them to behave themselves and get along.\\n\\nThe cat and the dog felt ashamed of themselves. They realized that they had hurt each other and their owner. They apologized to each other and to their owner. They promised to be nicer to each other and share their things. They hugged each other and licked each other's faces.\\n\\nFrom that day on, they became friends. They played together, slept together, and ate together. They learned to respect each other's differences and appreciate each other's strengths. They were happy and content.\\n\\nThe end.\",\n",
       " 'output': 'The story \"The Cat and the Dog\" tells of a cat named Silvester and a dog who live together but often fight. One day, Silvester plays a prank on the dog by tying yarn to his tail, which leads to a big fight. Their owner intervenes, scolds them, and nurses their wounds. Feeling ashamed, the cat and dog apologize and promise to be friends. From then on, they get along, play together, and appreciate each other\\'s qualities.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the string module\n",
    "import string\n",
    "\n",
    "# Define the function\n",
    "def rename_cat(inputs: dict) -> dict:\n",
    "  # Open the file in read mode\n",
    "  text = inputs[\"text\"]\n",
    "  # Create a table that maps punctuation characters to None\n",
    "  new_text = text.replace('cat', 'Silvester the Cat')\n",
    "  # Apply the table to the text and return the result\n",
    "  return {\"output_text\": new_text}\n",
    "\n",
    "with open(\"data/Cats&Dogs.txt\") as f: \n",
    "    cats_and_dogs= f.read() \n",
    "    \n",
    "transform_chain = TransformChain(\n",
    "    input_variables=[\"text\"], output_variables=[\"output_text\"], \n",
    "    transform=rename_cat\n",
    ")\n",
    "template = \"\"\"Summarize this text: \n",
    "\n",
    "{output_text}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"output_text\"], template=template)\n",
    "llm_chain = LLMChain(llm=model, prompt=prompt)\n",
    "\n",
    "sequential_chain = SimpleSequentialChain(chains=[transform_chain, \n",
    "llm_chain])\n",
    "\n",
    "sequential_chain.invoke(cats_and_dogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Agents \n",
    "\n",
    "Agents are entities that drive decision-making within LLM-powered apps. \n",
    "Agent types: \n",
    "- Structured input ReAct. \n",
    "- OpenAI Functions. \n",
    "- Conversational \n",
    "- Self ask with search. \n",
    "- ReAct document store. \n",
    "- Plan-and-execute agents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Conversational Applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a plain vanilla bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    HumanMessage, \n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "from langchain.memory import ConversationBufferMemory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! Rome is a city rich in history, art, and culture. With only 2 days, you'll want to focus on the must-see attractions. Here's a suggested itinerary:\n",
      "\n",
      "### Day 1: Ancient Rome\n",
      "**Morning:**\n",
      "1. **Colosseum**: Start your day early to avoid crowds. The Colosseum is one of Rome's most iconic landmarks.\n",
      "2. **Roman Forum**: Just next to the Colosseum, the Roman Forum was the political and economic hub of the Roman Republic.\n",
      "\n",
      "**Afternoon:**\n",
      "3. **Palatine Hill**: Explore the ruins of ancient palaces and temples. It's a short walk from the Roman Forum.\n",
      "4. **Pantheon**: Head to the historic center to visit this ancient temple, now a church. It's one of the best-preserved ancient Roman buildings.\n",
      "\n",
      "**Evening:**\n",
      "5. **Piazza Navona**: Enjoy the beautiful fountains and architecture. It's a great place to relax and people-watch.\n",
      "6. **Dinner**: Try some authentic Italian cuisine in one of the nearby restaurants.\n",
      "\n",
      "### Day 2: Vatican City and Historic Sites\n",
      "**Morning:**\n",
      "1. **Vatican City**: Start early to visit St. Peter's Basilica and the Vatican Museums, including the Sistine Chapel.\n",
      "2. **St. Peter's Square**: Take some time to admire the architecture and the famous obelisk.\n",
      "\n",
      "**Afternoon:**\n",
      "3. **Castel Sant'Angelo**: Walk along the Tiber River to reach this historic castle, which offers great views of the city.\n",
      "4. **Trevi Fountain**: Make a wish and toss a coin into the famous fountain.\n",
      "\n",
      "**Evening:**\n",
      "5. **Spanish Steps**: Climb the steps and enjoy the view of the Piazza di Spagna.\n",
      "6. **Dinner**: End your day with a delicious Italian meal in one of the local trattorias.\n",
      "\n",
      "### Tips:\n",
      "- **Transportation**: Rome is very walkable, but you can also use public transportation like buses and the metro.\n",
      "- **Tickets**: Book your tickets for the Colosseum, Vatican Museums, and other popular attractions in advance to save time.\n",
      "- **Comfortable Shoes**: You'll be doing a lot of walking, so make sure to wear comfortable shoes.\n",
      "- **Hydration**: Carry a water bottle, especially during the summer months.\n",
      "\n",
      "Enjoy your trip to Rome!\n"
     ]
    }
   ],
   "source": [
    "chat = ChatMistralAI(\n",
    "    api_key=mistral_api_key,\n",
    "    model_name=\"mistral-large-latest\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that help the user to plan an optimized itinerary.\"),\n",
    "    HumanMessage(content=\"I'm going to Rome for 2 days, what can I visit?\")\n",
    "]\n",
    "\n",
    "output = chat(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Hello! How are you today? I'm here and ready to chat about all sorts of things. Let's make this conversation interesting! How about I share a fun fact to start? Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that amazing? Now, it's your turn to share something or ask me a question.\n"
     ]
    }
   ],
   "source": [
    "# Adding memory \n",
    "memory = ConversationBufferMemory() \n",
    "conversation = ConversationChain(\n",
    "    llm=chat, verbose=True, memory=memory\n",
    ")\n",
    "\n",
    "print(conversation.run(\"Hi there!\").replace(\"\\\\n\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How are you today? I'm here and ready to chat about all sorts of things. Let's make this conversation interesting! How about I share a fun fact to start? Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that amazing? Now, it's your turn to share something or ask me a question.\n",
      "Human: What's the best place to live in Kenya?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "That's a great question! Determining the \"best\" place to live can depend on various factors such as personal preferences, lifestyle, and specific needs. However, I can tell you about some popular and highly-regarded places to live in Kenya.\n",
      "\n",
      "1. **Nairobi**: As the capital city, Nairobi offers a mix of modern amenities and cultural experiences. It has vibrant neighborhoods like Westlands, Karen, and Lavington, which are known for their upscale living, excellent schools, and numerous recreational facilities. However, traffic and pollution can be downsides.\n",
      "\n",
      "2. **Mombasa**: If you love coastal living, Mombasa is a fantastic choice. It offers beautiful beaches, a rich cultural heritage, and a more relaxed pace of life. Areas like Nyali and Diani are particularly popular for their scenic beauty and high-end properties.\n",
      "\n",
      "3. **Kisumu**: Located on the shores of Lake Victoria, Kisumu is known for its tranquil environment and stunning sunsets. It is a great place for those who enjoy outdoor activities and a slower pace of life compared to Nairobi.\n",
      "\n",
      "4. **Nakuru**: Often referred to as the cleanest town in East Africa, Nakuru is known for its picturesque landscapes and the nearby Lake Nakuru National Park, famous for its flamingos. It offers a balanced mix of urban amenities and natural beauty.\n",
      "\n",
      "5. **Naivasha**: This town is popular for its serene environment and proximity to Lake Naivasha. It is ideal for those who enjoy outdoor activities like hiking, boating, and birdwatching. The area is also known for its flower farms.\n",
      "\n",
      "Ultimately, the best place to live depends on what you prioritize—whether it's city life, natural beauty, or a mix of both. If you have specific preferences or needs, feel free to share, and I can give more tailored suggestions!\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(\"What's the best place to live in Kenya?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How are you today? I'm here and ready to chat about all sorts of things. Let's make this conversation interesting! How about I share a fun fact to start? Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that amazing? Now, it's your turn to share something or ask me a question.\n",
      "Human: What's the best place to live in Kenya?\n",
      "AI: That's a great question! Determining the \"best\" place to live can depend on various factors such as personal preferences, lifestyle, and specific needs. However, I can tell you about some popular and highly-regarded places to live in Kenya.\n",
      "\n",
      "1. **Nairobi**: As the capital city, Nairobi offers a mix of modern amenities and cultural experiences. It has vibrant neighborhoods like Westlands, Karen, and Lavington, which are known for their upscale living, excellent schools, and numerous recreational facilities. However, traffic and pollution can be downsides.\n",
      "\n",
      "2. **Mombasa**: If you love coastal living, Mombasa is a fantastic choice. It offers beautiful beaches, a rich cultural heritage, and a more relaxed pace of life. Areas like Nyali and Diani are particularly popular for their scenic beauty and high-end properties.\n",
      "\n",
      "3. **Kisumu**: Located on the shores of Lake Victoria, Kisumu is known for its tranquil environment and stunning sunsets. It is a great place for those who enjoy outdoor activities and a slower pace of life compared to Nairobi.\n",
      "\n",
      "4. **Nakuru**: Often referred to as the cleanest town in East Africa, Nakuru is known for its picturesque landscapes and the nearby Lake Nakuru National Park, famous for its flamingos. It offers a balanced mix of urban amenities and natural beauty.\n",
      "\n",
      "5. **Naivasha**: This town is popular for its serene environment and proximity to Lake Naivasha. It is ideal for those who enjoy outdoor activities like hiking, boating, and birdwatching. The area is also known for its flower farms.\n",
      "\n",
      "Ultimately, the best place to live depends on what you prioritize—whether it's city life, natural beauty, or a mix of both. If you have specific preferences or needs, feel free to share, and I can give more tailored suggestions!\n",
      "Human: \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User:  \n",
      "AI System:  It seems like you might be considering or just curious about different places to live in Kenya. Do you have any particular interests or deal-breakers that could help narrow down the suggestions? For example, are you looking for a place with a vibrant nightlife, or perhaps a quiet town with good schools for children? Also, have you ever visited Kenya before? I'd love to hear about your experiences or expectations!\n",
      "\n",
      "If you're up for it, I can also share some unique facts or stories about each place. For instance, did you know that the Great Rift Valley, which runs through Nakuru and Naivasha, is believed to be the cradle of humanity? Many famous fossils, like the \"Turkana Boy,\" have been discovered in this region. It's pretty amazing to think that we can trace our origins back to Kenya!\n",
      "\n",
      "On the other hand, if you're leaning towards a more urban lifestyle, Nairobi has a lot to offer, including a thriving tech scene. It's often referred to as the \"Silicon Savannah\" because of its rapid growth in tech startups and innovations, like the mobile money transfer service M-Pesa.\n",
      "\n",
      "I'm here to provide as much information as you'd like, so just let me know how you'd like to proceed.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! How are you today? I'm here and ready to chat about all sorts of things. Let's make this conversation interesting! How about I share a fun fact to start? Did you know that a day on Venus is longer than a year on Venus? It takes Venus about 243 Earth days to rotate once on its axis, but it only takes around 225 Earth days for Venus to orbit the Sun. Isn't that amazing? Now, it's your turn to share something or ask me a question.\n",
      "Human: What's the best place to live in Kenya?\n",
      "AI: That's a great question! Determining the \"best\" place to live can depend on various factors such as personal preferences, lifestyle, and specific needs. However, I can tell you about some popular and highly-regarded places to live in Kenya.\n",
      "\n",
      "1. **Nairobi**: As the capital city, Nairobi offers a mix of modern amenities and cultural experiences. It has vibrant neighborhoods like Westlands, Karen, and Lavington, which are known for their upscale living, excellent schools, and numerous recreational facilities. However, traffic and pollution can be downsides.\n",
      "\n",
      "2. **Mombasa**: If you love coastal living, Mombasa is a fantastic choice. It offers beautiful beaches, a rich cultural heritage, and a more relaxed pace of life. Areas like Nyali and Diani are particularly popular for their scenic beauty and high-end properties.\n",
      "\n",
      "3. **Kisumu**: Located on the shores of Lake Victoria, Kisumu is known for its tranquil environment and stunning sunsets. It is a great place for those who enjoy outdoor activities and a slower pace of life compared to Nairobi.\n",
      "\n",
      "4. **Nakuru**: Often referred to as the cleanest town in East Africa, Nakuru is known for its picturesque landscapes and the nearby Lake Nakuru National Park, famous for its flamingos. It offers a balanced mix of urban amenities and natural beauty.\n",
      "\n",
      "5. **Naivasha**: This town is popular for its serene environment and proximity to Lake Naivasha. It is ideal for those who enjoy outdoor activities like hiking, boating, and birdwatching. The area is also known for its flower farms.\n",
      "\n",
      "Ultimately, the best place to live depends on what you prioritize—whether it's city life, natural beauty, or a mix of both. If you have specific preferences or needs, feel free to share, and I can give more tailored suggestions!\n",
      "Human: \n",
      "AI: It seems like you might be considering or just curious about different places to live in Kenya. Do you have any particular interests or deal-breakers that could help narrow down the suggestions? For example, are you looking for a place with a vibrant nightlife, or perhaps a quiet town with good schools for children? Also, have you ever visited Kenya before? I'd love to hear about your experiences or expectations!\n",
      "\n",
      "If you're up for it, I can also share some unique facts or stories about each place. For instance, did you know that the Great Rift Valley, which runs through Nakuru and Naivasha, is believed to be the cradle of humanity? Many famous fossils, like the \"Turkana Boy,\" have been discovered in this region. It's pretty amazing to think that we can trace our origins back to Kenya!\n",
      "\n",
      "On the other hand, if you're leaning towards a more urban lifestyle, Nairobi has a lot to offer, including a thriving tech scene. It's often referred to as the \"Silicon Savannah\" because of its rapid growth in tech startups and innovations, like the mobile money transfer service M-Pesa.\n",
      "\n",
      "I'm here to provide as much information as you'd like, so just let me know how you'd like to proceed.\n",
      "Human: thank you\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "User:  thank you\n",
      "AI System:  You're very welcome! I'm glad I could help. If you have any more questions about Kenya or any other topic, feel free to ask. I'm here to make our conversation enjoyable and informative.\n",
      "\n",
      "To keep our chat going, would you like to learn a bit of Swahili, one of the official languages of Kenya? For example, \"Jambo\" is a common greeting that means \"Hello.\" And \"Asante\" means \"Thank you.\" It's always fun to learn a few phrases from different languages!\n",
      "\n",
      "Or, if you prefer, we can switch gears entirely. How about a lighthearted topic? Have you watched any interesting movies or TV shows lately? I can provide recommendations if you're looking for something new to watch.\n",
      "\n",
      "The choice is yours! Let's make this conversation engaging and fun. What would you like to talk about or learn next?\n"
     ]
    }
   ],
   "source": [
    "# Interactive chat \n",
    "while True: \n",
    "    query = input(\"you: \")\n",
    "    if query == 'q': \n",
    "        break \n",
    "    output = conversation({'input': query})\n",
    "    print('User: ', query)\n",
    "    print(\"AI System: \", output['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "5 \n",
      "2.3 The need for Cloud Policy  \n",
      "The cloud computing landscape is robust and needs adequate policy and legal framework to ensure. \n",
      "The Kenya's existing policy and legal framework is inadequate and doesn’t address all the issues \n",
      "and challenges related to cloud computing hence the need to come up with a comprehensive cloud \n",
      "policy.  While general ICT principles are outlined, there may be gaps in addressing the traditional \n",
      "on-premise challenges and opportunities associated with cloud computing. The establishment of a \n",
      "Cloud Policy in Kenya prese nts an opportunity to address gaps in the existing policy and legal \n",
      "framework related to cloud computing. By defining clear objectives, enhancing the legal \n",
      "framework, and promoting best practices, Kenya can position itself as a leader in cloud computing, \n",
      "driving innovation, efficiency, and competitiveness in the digital economy. \n",
      "The Kenya Cloud Policy builds upon the foundational principles and objectives outlined in \n",
      "National ICT Policy, which serves as the overarching framework guiding ICT development and \n",
      "governance in the country. This policy acknowledges the importance of lever aging cloud \n",
      "computing technologies to accelerate digital transformation, enhance service delivery, and drive \n",
      "economic growth, while ensuring alignment with existing legal frameworks and regulatory \n",
      "requirements. \n",
      "2.4 Current State \n",
      "Most organizations typically host their data and systems on -premise by managing their own IT\n",
      "\n",
      "MINISTRY OF INFORMATION, COMMUNICATIONS AND THE DIGITAL ECONOMY \n",
      "KENYA CLOUD POLICY \n",
      "2024\n",
      "\n",
      "19 \n",
      "4.2 Governance \n",
      "To ensure smooth implementation and achieve optimal results, a clearly defined governance \n",
      "structure is essential. Six primary roles have been identified to govern the implementation of the \n",
      "Kenya Cloud Policy. \n",
      "S/No Item Responsible Organ Roles \n",
      "1 Policy Body Ministry of Information, \n",
      "Communications and the \n",
      "Digital Economy. \n",
      "• Defining the objectives and \n",
      "scope of the Kenya Cloud \n",
      "Policy. \n",
      "• Setting the guidelines for the \n",
      "policy and publishing. \n",
      "• Defining the roles and \n",
      "responsibilities of the \n",
      "different involved entities, in \n",
      "the context of the Cloud \n",
      "Policy. \n",
      "• Updating and adjusting the \n",
      "Kenya Cloud Policy when \n",
      "required. \n",
      "2 Cloud Adoption \n",
      "Committee  \n",
      " \n",
      "Multi-agency committee to \n",
      "be constituted by the PS \n",
      "responsible for ICT \n",
      "• Oversee cloud adoption \n",
      "across the different entities \n",
      "through pilots and supporting \n",
      "Entities during the migration \n",
      "process with technical and \n",
      "commercial expertise. \n",
      "• Checking the cybersecurity, \n",
      "technical and commercial \n",
      "requirements.\n",
      "\n",
      "13 \n",
      "3 CHAPTER THREE: POLICY STATEMENT \n",
      "3.1 Objectives \n",
      "The Kenya Cloud Policy shall mandate all entities to prioritize cloud-based solutions when making \n",
      "ICT investments (procurement of hardware, software, renewal of existing software licenses, \n",
      "revamping existing ICT infrastructure including Data Centers). This prioritization aims to achieve \n",
      "the following key objectives: \n",
      "i. To accelerate adoption of green cloud computing technology  \n",
      "ii. To reduce Total Cost of Ownership of ICT infrastructure \n",
      "iii. To ensure robust Cybersecurity measures on data hosted on cloud. \n",
      "iv. To enable collaboration and interoperability among entities. \n",
      "v. To promote Data Residency and Sovereignty. \n",
      " \n",
      "3.2 Statements \n",
      "When making new IT investments, entities covered by this policy are required to consider the \n",
      "below stages: \n",
      " \n",
      "a) A ‘New ICT investment’ includes procurement of new hardware and software, renewal of \n",
      "hardware and renewal of present software licenses. It is noteworthy that the entities falling \n",
      "under the scope of this policy must abide by the laws, regulations and controls relate d to \n",
      "data classification and other regulations regarding the location of hosting their data in any \n",
      "way.  \n",
      "b) If data is classified as top secret or secret, the government cloud service providers should \n",
      "be relied upon only if the technical and cybersecurity requirements are met. In the case that \n",
      "the government cloud service providers do not meet the technical and the cybersecurity\n",
      "Human: Give an overview of the kenya cloud policy.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, here's an overview of the Kenya Cloud Policy:\n",
      "\n",
      "**Purpose:**\n",
      "The Kenya Cloud Policy is designed to address gaps in the existing policy and legal framework related to cloud computing, driving innovation, efficiency, and competitiveness in the digital economy. It builds upon the principles and objectives outlined in the National ICT Policy.\n",
      "\n",
      "**Objectives:**\n",
      "1. To accelerate the adoption of green cloud computing technology.\n",
      "2. To reduce the Total Cost of Ownership of ICT infrastructure.\n",
      "3. To ensure robust cybersecurity measures on data hosted on the cloud.\n",
      "4. To enable collaboration and interoperability among entities.\n",
      "5. To promote Data Residency and Sovereignty.\n",
      "\n",
      "**Scope:**\n",
      "The policy mandates all entities to prioritize cloud-based solutions when making ICT investments, including procurement of hardware and software, renewal of licenses, and revamping existing ICT infrastructure.\n",
      "\n",
      "**Governance:**\n",
      "A clearly defined governance structure with six primary roles has been identified to oversee the implementation of the policy. The key roles are:\n",
      "1. **Policy Body:** Ministry of Information, Communications and the Digital Economy.\n",
      "2. **Cloud Adoption Committee:** A multi-agency committee to oversee cloud adoption and support entities during the migration process.\n",
      "\n",
      "**Compliance:**\n",
      "Entities covered by this policy must abide by the laws, regulations, and controls related to data classification and other regulations regarding the location of hosting their data. For data classified as top secret or secret, government cloud service providers should be used only if they meet the technical and cybersecurity requirements.\n",
      "\n",
      "**Policy Statements:**\n",
      "The policy provides specific statements and guidelines for entities to consider when making new IT investments.\n",
      "\n",
      "This overview is based on the provided context, and there might be more aspects to the Kenya Cloud Policy not covered here.\n"
     ]
    }
   ],
   "source": [
    "# Adding non-parametric knowledge \n",
    "import warnings\n",
    "from langchain_mistralai import MistralAIEmbeddings \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS \n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import ConversationalRetrievalChain \n",
    "from langchain.memory import ConversationBufferMemory \n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "mistral_embeddings = MistralAIEmbeddings(\n",
    "    api_key=mistral_api_key,\n",
    "    model=\"mistral-embed\"\n",
    ")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200 \n",
    ")\n",
    "raw_documents = PyPDFLoader(\"data/Kenya_Cloud_Policy.pdf\").load() \n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, mistral_embeddings)\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "llm = model \n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    memory=memory, \n",
    "    verbose=True\n",
    ")\n",
    "print(qa_chain.run({'question': 'Give an overview of the kenya cloud policy.'}).replace(\"\\\\n\", '\\n'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the bot agentic(from the langchain.agents.agent_toolkits). \n",
    "- create_retriever_tool: Creates a custom tool that acts as a retriever for an agent. \n",
    "- create_conversational_retrieval_agent: Initializes a conversational agent that is configured to work with retrievers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import (create_retriever_tool,\n",
    "                                            create_conversational_retrieval_agent)\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    db.as_retriever(), \n",
    "    \"Kenya Cloud Policy\", \n",
    "    \"Search and return documents regarding the Kenya Cloud Policy.\"\n",
    ")\n",
    "tools = [tool]\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    return_messages=True\n",
    ")\n",
    "agent_executor = create_conversational_retrieval_agent(llm, \n",
    "    tools, \n",
    "    memory_key='chat_history', \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor({\"input\": \"Briefly explain the Kenya Cloud Policy.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper() \n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run, \n",
    "        name='Search', \n",
    "        description=\"Useful to answer questions about current events.\"\n",
    "    ), \n",
    "    create_retriever_tool(\n",
    "        db.as_retriever(), \n",
    "        \"Kenya Cloud Policy\",\n",
    "        \"Searches and returns documents regarding the Kenya Cloud Policy.\"\n",
    "    )\n",
    "]\n",
    "agent_executor = create_conversational_retrieval_agent(\n",
    "    llm, \n",
    "    tools, \n",
    "    memory_key='chat memory', \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "agent_executor({\"input\": \"What is the Kenya Cloud Policy?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search and Recommendation Engines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
